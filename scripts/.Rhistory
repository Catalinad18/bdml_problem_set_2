panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_text(size=6))
head(upla)
ggplot()+
geom_sf(data=upla, aes(fill = UPlArea)) +
theme_bw() +
theme(axis.title =element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_text(size=6))
ggplot()+
geom_sf(data=upla %>% filter(grepl("RIO",UPlNombre)==FALSE),size=.3,fill=NA) +
#filtramos usando expresiones regulares
geom_sf(data=colegios[1:250,],shape=18) + #utilizamos solo los primeros 250 col
egios y los representamos con romboides (shape=18)
ggplot()+
geom_sf(data=upla %>% filter(grepl("RIO",UPlNombre)==FALSE),size=.3,fill=NA) + #filtramos usando expresiones regulares
geom_sf(data=colegios[1:250,],shape=18) + #utilizamos solo los primeros 250 colegios y los representamos con romboides (shape=18)
geom_sf(data=ciclovias,col="red") +
theme_bw() +
theme(axis.title =element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_text(size=6))
st_crs(ciclovias)
st_crs(colegios) #MAGNA-SIRGAS
cilovias<-st_transform(ciclovias,4686)
st_crs(ciclovias)
db<-data.frame(place=c("Uniandes","Banco de La Republica"),lat=c(4.601590,4.60215
1), long=c(-74.066391,-74.072350), nudge_y=c(-0.001,0.001))
db<-data.frame(place=c("Uniandes","Banco de La Republica"),lat=c(4.601590,4.602151), long=c(-74.066391,-74.072350), nudge_y=c(-0.001,0.001))
db<-db %>% mutate(latp=lat,longp=long)
db<-st_as_sf(db,coords=c('longp','latp'),crs=4326)
db
db<-st_transform(db,4686)
st_crs(db)
ggplot()+
geom_sf(data=upla %>% filter(UPlNombre%in%c("LA CANDELARIA","LAS NIEVES")), fil
l = NA) +
ggplot()+
geom_sf(data=upla %>% filter(UPlNombre%in%c("LA CANDELARIA","LAS NIEVES")), fill = NA) +
geom_sf(data=db, col="red") +
geom_label(data = db, aes(x = long, y = lat, label = place),
size = 3, col = "black", fontface = "bold", nudge_y =db$nudge_y) +
theme_bw() +
theme(axis.title =element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_text(size=6))
st_distance(db)
ciclovias<-st_transform(ciclovias, 4686)
db<-st_transform(db, 4686)
st_distance(db,ciclovias)
Datos Espaciales. Fundamentos teóricos. https://bloqueneon.uniandes.edu.co//content/enforced/211813-UN_202...
ciclovias<-st_transform(ciclovias, 4686)
db<-st_transform(db, 4686)
st_distance(db,ciclovias)
ggplot()+
geom_sf(data=ciclovias[8,], fill = NA) +
geom_sf(data=db, col="red") +
theme_bw() +
theme(axis.title =element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_text(size=6))
upla<-st_transform(upla,crs=st_crs(db))
db<- st_join(db,upla,join=st_intersects)
head(db)
require("pacman")
p_load(tidyverse, sf, tmaptools) #La librería tmaptools contiene la función geocode_OSM() que se conecta a la API de OpenStreetMap. Este retorna las coordenadas geográ􀀁cas del sitio/dirección buscado.
geocode_OSM("Casa de Nariño, Bogotá")
require("pacman")
p_load(tidyverse, sf, tmaptools) #La librería tmaptools contiene la función geocode_OSM() que se conecta a la API de OpenStreetMap. Este retorna las coordenadas geográ􀀁cas del sitio/dirección buscado.
geocode_OSM("Casa de Nariño, Bogotá")
geocode_OSM("Casa Rosada, Buenos Aires",as.sf=TRUE)
p_load("osmdata")
available_features() %>% head(20)
available_tags("amenity") #Cada feature contiene una lista de tags , que describe un atributo geográ􀀁co de la feature seleccionada. Por ejemplo, podemos ver los tags disponibles para la feature amenity con la función available_tags()
require("pacman")
p_load(tidyverse, sf, tmaptools) #La librería tmaptools contiene la función geocode_OSM() que se conecta a la API de OpenStreetMap. Este retorna las coordenadas geográ􀀁cas del sitio/dirección buscado.
geocode_OSM("Casa de Nariño, Bogotá")
geocode_OSM("Casa Rosada, Buenos Aires",as.sf=TRUE)
p_load("osmdata")
available_features() %>% head(20)
available_tags("amenity") #Cada feature contiene una lista de tags , que describe un atributo geográ􀀁co de la feature seleccionada. Por ejemplo, podemos ver los tags disponibles para la feature amenity con la función available_tags()
bogota<-opq(bbox = getbb("Bogotá Colombia"))
bogota
universidades<- bogota %>%
add_osm_feature(key="amenity",value="university") %>% # de las amenities disponibles, seleccionamos las universidades
osmdata_sf() #transformamos a un objeto sf
puntos_universidades<-universidades$osm_point
head(puntos_universidades)
ggplot()+
geom_sf(data=puntos_universidades) +
theme_bw()
ggplot()+
geom_sf(data=puntos_universidades) +
theme_bw()
ML<-universidades$osm_polygons %>% filter(grepl("Mario Laserna" ,name))
ML
ggplot()+
geom_sf(data=ML) +
theme_bw()
p_load("leaflet")
leaflet() %>%
addTiles() %>%  #capa base
addPolygons(data=ML) #capa edificio ML
leaflet() %>%
addProviderTiles(providers$Stamen.Toner) %>%  #capa base
addCircles(data=puntos_universidades, popup = ~name) %>%  #agregamos puntos con un `pop up` que indica el nombre
addPolygons(data=ML) #capa edificio ML
install.packages("pdftools")
library(pdftools)
acuerdo_final <- pdf_text("C:/Users/PC/Documents/Uniandes/Economía/Big Data y Machine Learning para Economía Aplicada/Semana 7/acuerdo_final.pdf")
documento <- ""
for (pagina in 1:length(acuerdo_final)) {
documento <- paste(documento, acuerdo_final[pagina])
}
substr(documento, 1, 500)
library(stringi)
documento <- stri_trans_general(str = documento, id = "Latin-ASCII")
substr(documento, 1, 500)
documento <- gsub('[^A-Za-z0-9 ]+', ' ', documento)
substr(documento, 1, 1000)
# Minúsculas
documento <- tolower(documento)
# Espacios
documento <- gsub('\\s+', ' ', documento)
substr(documento, 1, 1000)
documento <- gsub("\\d+", "", documento)
documento <- gsub('\\s+', ' ', documento)
documento <- trimws(documento)
substr(documento, 1, 1000)
library(tokenizers)
install.packages("tokenizers")
library(tokenizers)
documento_tokenizado <- tokenize_words(documento)
length(unique(documento_tokenizado[[1]]))
lista_palabras1 <- stopwords(language = "es", source = "snowball")
lista_palabras1 <- stopwords(language = "es", source = "snowball")
lista_palabras <- union(lista_palabras1, lista_palabras2)
lista_palabras
install.packages("stopwords")
library(stopwords)
# Descargamos la lista de las stopwords en español de dos fuentes diferentes y las combinamos
lista_palabras1 <- stopwords(language = "es", source = "snowball")
lista_palabras2 <- stopwords(language = "es", source = "nltk")
lista_palabras <- union(lista_palabras1, lista_palabras2)
lista_palabras
documento_tokenizado <- documento_tokenizado[[1]]
n0 <- length(documento_tokenizado)
documento_tokenizado <- setdiff(documento_tokenizado, lista_palabras)
n1 <- length(documento_tokenizado)
n0 - n1
install.packages("SnowballC")
library(SnowballC)
library(SnowballC)
documento_tokenizado <- wordStem(documento_tokenizado, "spanish")
documento_tokenizado[1:500]
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
library(tidyverse)
frecuencia <- documento_tokenizado %>%
table() %>%
data.frame() %>%
rename("Palabra" = ".") %>%
arrange(desc(Freq))
set.seed(666)
png(filename = "wordcloud.png", width = 800, height = 800)
wordcloud(words = frecuencia$Palabra, freq = frecuencia$Freq, min.freq = 1,
max.words = 200, random.order=  FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"))
dev.off()
require(pacman)
p_load(tidyverse,caret, gtsummary)
set.seed(12)
credit <- readRDS(url("https://github.com/ignaciomsarmiento/datasets/blob/main/credit_class.rds?raw=true"))
head(credit)
tbl_summary(credit, by = Default, statistic = list(all_continuous() ~ "{mean} ({sd})"))
credit<-credit %>% mutate(Default=factor(Default,levels=c(1,0),labels=c("Sí","No")))
credit = credit %>%
mutate(historygood  = ifelse(test = history == "good",
yes = 1,
no = 0))
credit = credit %>%
mutate(historypoor = ifelse(test = history == "poor",
yes = 1,
no = 0))
credit = credit %>%
mutate(purposeusedcar = ifelse(test = purpose == "usedcar",
yes = 1,
no = 0))
credit = credit %>%
mutate(purposegoods.repair = ifelse(test = purpose == "goods.repair",
yes = 1,
no = 0))
credit = credit %>%
mutate(purposeedu= ifelse(test = purpose == "edu",
yes = 1,
no = 0))
credit = credit %>%
mutate(foreigngerman= ifelse(test = foreign == "foreign",
yes = 1,
no = 0))
credit = credit %>%
mutate(rentTRUE= ifelse(test = rent == "TRUE",
yes = 1,
no = 0))
inTrain <- createDataPartition(
y = credit$Default,## La variable dependiente u objetivo
p = .7, ## Usamos 70%  de los datos en el conjunto de entrenamiento
list = FALSE)
training <- credit[ inTrain,]
testing  <- credit[-inTrain,]
nrow(training)
ctrl_def <- trainControl(
method = "cv",
summaryFunction = defaultSummary, #medida de rendimiento
number = 5) # número de folds
modelo_def <- train(Default ~ amount+installment+age+ historygood + historypoor + purposeusedcar+ purposegoods.repair + purposeedu + foreigngerman + rentTRUE,
data = training,
method = "glm", #for logit
trControl = ctrl_def,
family = "binomial",
preProcess = c("center", "scale")) # preprocesamiento de los datos
modelo_def
prediccion_def <- predict(modelo_def, newdata = testing)
confusionMatrix(prediccion_def, testing$Default)
control_two <- trainControl(method = "cv",
number = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
modelo_two <- train( Default ~amount+installment+age+ historygood + historypoor + purposeusedcar+ purposegoods.repair + purposeedu + foreigngerman + rentTRUE,
data = training,
method = "glm", #for logit
trControl = control_two,
family = "binomial",
metric = 'ROC',
preProcess = c("center", "scale") ) # preprocesamiento de los datos
modelo_two
fiveStats <- function(...) c(twoClassSummary(...), defaultSummary(...))
ctrl<- trainControl(method = "cv",
number = 5,
summaryFunction = fiveStats,
classProbs = TRUE,
verbose=FALSE,
savePredictions = T)
modelo <- train(Default ~amount+installment+age+ historygood + historypoor + purposeusedcar+ purposegoods.repair + purposeedu + foreigngerman + rentTRUE,
data = training,
method = "glm", #for logit
trControl = ctrl,
family = "binomial",
metric = 'ROC',
preProcess = c("center", "scale") )
modelo
library(pacman)
p_load(tidyverse, tidymodels, glmnet, stargazer)
file_dir <- this.path::here()
setwd(file_dir)
df <- read_csv("../stores/train.csv")
df_test <- read_csv(("../stores/test.csv"))
glimpse(df)
glimpse(df_test)
sapply(df, function(x) sum(is.na(x)))
View(df)
mediana_sup_cubierta <- median(df$surface_covered, na.rm = TRUE)
mediana_sup_total <- median(df$surface_total, na.rm = TRUE)
mediana_bathrooms <- median(df$bathrooms, na.rm = TRUE)
mediana_rooms <- median(df$rooms, na.rm = TRUE)
df <- df %>%
mutate(rooms = replace_na(rooms, 3),
bathrooms = replace_na(bathrooms, 3),
surface_covered = replace_na(surface_covered, mediana_sup_cubierta),
surface_total = replace_na(surface_total, mediana_sup_total),)
sapply(df, function(x) sum(is.na(x)))
property_type_d <- c("property_type")
df <- df %>% mutate_at(property_type_d, as.factor)
df <- df %>% mutate_at(property_type, as.factor)
df <- df %>% mutate_at(df$property_type, as.factor)
cls
library(pacman)
p_load(tidyverse, tidymodels, glmnet, stargazer)
file_dir <- this.path::here()
setwd(file_dir)
df <- read_csv("../stores/train.csv")
df_test <- read_csv(("../stores/test.csv"))
mediana_sup_cubierta <- median(df$surface_covered, na.rm = TRUE) #108
mediana_sup_total <- median(df$surface_total, na.rm = TRUE) #119
mediana_bathrooms <- median(df$bathrooms, na.rm = TRUE) #3
mediana_rooms <- median(df$rooms, na.rm = TRUE) #3
df <- df %>%
mutate(rooms = replace_na(rooms, 3),
bathrooms = replace_na(bathrooms, 3),
surface_covered = replace_na(surface_covered, mediana_sup_cubierta),
surface_total = replace_na(surface_total, mediana_sup_total),)
sapply(df, function(x) sum(is.na(x)))
df <- df %>% mutate_at(df$property_type, as.factor)
library(pacman)
p_load(tidyverse, tidymodels, glmnet, stargazer, dplyr)
View(df)
View(df_test)
View(df_test)
property_typed <- ifelse(property_type == "Casa", 1, 0)
property_typed <- ifelse(df$property_type == "Casa", 1, 0)
df <- df %>%
property_typed <- ifelse(df$property_type == "Casa", 1, 0)
df <- df %>%
mutate(property_type <- ifelse(df$property_type == "Casa", 1, 0))
View(df)
df <- df %>%
mutate(property_typed <- ifelse(df$property_type == "Casa", 1, 0))
df <- df %>%
mutate(property_typed = ifelse(df$property_type == "Casa", 1, 0))
#Problem Set 2
#Cargamos paquetes requeridos
library(pacman)
p_load(tidyverse, tidymodels, glmnet, stargazer, dplyr)
#Cargamos data-frames
file_dir <- this.path::here()
setwd(file_dir)
df <- read_csv("../stores/train.csv")
df_test <- read_csv(("../stores/test.csv"))
mediana_sup_cubierta <- median(df$surface_covered, na.rm = TRUE) #108
mediana_sup_total <- median(df$surface_total, na.rm = TRUE) #119
mediana_bathrooms <- median(df$bathrooms, na.rm = TRUE) #3
mediana_rooms <- median(df$rooms, na.rm = TRUE) #3
df <- df %>%
mutate(rooms = replace_na(rooms, 3),
bathrooms = replace_na(bathrooms, 3),
surface_covered = replace_na(surface_covered, mediana_sup_cubierta),
surface_total = replace_na(surface_total, mediana_sup_total),)
df <- df %>%
mutate(property_typed = ifelse(df$property_type == "Casa", 1, 0))
sapply(df, function(x) sum(is.na(x)))
distributionPrice <- function (pricee) {
N = length(df$price)
pricee <- na.omit(df$price)
hist( df$price,col = "light blue")
}
distributionPrice
distributionPrice
distributionBathrooms <- function (bathrooms) {
N = length(df$bathrooms)
bathrooms <- na.omit(df$bathrooms)
hist( df$bathrooms,col = "light blue")
}
distributionBathrooms
View(distributionPrice)
distributionPrice()
df <- df %>% mutate(price = log(price)
distributionPrice <- function (pricee) {
View(df)
df <- df %>% mutate(price = log(price))
distributionPrice <- function (pricee) {
N = length(df$price)
pricee <- na.omit(df$price)
hist( df$price,col = "light blue")
}
distributionPrice()
rec1
rec1 <- recipe(price ~ surface_total + surface_covered + rooms + bedrooms + bathrooms + property_typed, data = df)
rec1
lm_mod <- linear_reg()
wfl1 <- workflow() %>%
add_recipe(rec1) %>%
add_model(lm_mod)
fit1.1 <- wfl1 %>%
fit(data=df)
test_predict <- predict(fit1.1, new_data = df_test)
sapply(df_test, function(x) sum(is.na(x)))
distributionSurfaceTotalTest <- function (surface_totall) {
N = length(df_test$surface_total)
surface_totall <- na.omit(df_test$surface_total)
hist( df_test$surface_total,col = "light blue")
}
distributionSurfaceTotalTest()
View(df_test)
distributionSurfaceCoveredTest <- function (surface_coveredd) {
N = length(df_test$surface_covered)
surface_coveredd <- na.omit(df_test$surface_covered)
hist( df_test$surface_covered,col = "light blue")
}
distributionSurfaceCoveredTest()
distributionSurfaceTotalTest <- function (surface_totall) {
N = length(df_test$surface_total)
surface_totall <- na.omit(df_test$surface_total)
hist( df_test$surface_total,col = "light blue")
}
distributionSurfaceTotalTest()
distributionSurfaceCoveredTest <- function (surface_coveredd) {
N = length(df_test$surface_covered)
surface_coveredd <- na.omit(df_test$surface_covered)
hist( df_test$surface_covered,col = "light blue")
}
distributionSurfaceCoveredTest()
distributionRoomsTest <- function (rooms) {
N = length(df_test$rooms)
rooms <- na.omit(df_test$rooms)
hist( df_test$rooms,col = "light blue")
}
distributionRoomsTest()
distributionBathroomsTest <- function (bathrooms) {
N = length(df_test$bathrooms)
bathrooms <- na.omit(df_test$bathrooms)
hist( df_test$bathrooms,col = "light blue")
}
distributionBathroomsTest()
distributionSurfaceTotalTest <- function (surface_totall) {
N = length(df_test$surface_total)
surface_totall <- na.omit(df_test$surface_total)
hist( df_test$surface_total,col = "light blue")
}
distributionSurfaceTotalTest()
View(df_test)
mediana_sup_cubierta_test <- median(df_test$surface_covered, na.rm = TRUE) #108
mediana_sup_total_test <- median(df_test$surface_total, na.rm = TRUE) #119
mediana_bathrooms_test <- median(df_test$bathrooms, na.rm = TRUE) #3
mediana_rooms_test <- median(df_test$rooms, na.rm = TRUE) #3
df_test <- df_test %>%
mutate(rooms = replace_na(rooms, 2),
bathrooms = replace_na(bathrooms, 3),
surface_covered = replace_na(surface_covered, mediana_sup_cubierta_test),
surface_total = replace_na(surface_total, mediana_sup_total_test),)
df_test <- df_test %>%
mutate(property_typed = ifelse(df_test$property_type == "Casa", 1, 0))
test_predict <- predict(fit1.1, new_data = df_test)
View(test_predict)
test_rmse.1.1 <- rmse(test_predict, truth = price, estimate = .pred)
View(df)
View(df_test)
test_rmse.1.1 <- rmse(test_predict, truth = df_test$price, estimate = .pred)
set.seed(666)
data_split <- initial_split(df, prop = 7)
set.seed(666)
data_split <- initial_split(df, prop = .7)
train <- training(data_split)
test <- testing(data_split)
fit1.1 <- wfl1 %>%
fit(data=train)
test_predict <- predict(fit1.1, new_data = test)
test_rmse.1.1 <- rmse(test_predict, truth = price, estimate = .pred)
test_rmse.1.1 <- rmse(test_predict, truth = df$price, estimate = .pred)
library(pacman)
p_load(tidyverse, tidymodels, glmnet, stargazer, dplyr)
file_dir <- this.path::here()
setwd(file_dir)
df <- read_csv("../stores/train.csv")
df_test <- read_csv(("../stores/test.csv"))
mediana_sup_cubierta <- median(df$surface_covered, na.rm = TRUE) #118
mediana_sup_total <- median(df$surface_total, na.rm = TRUE) #120
mediana_bathrooms <- median(df$bathrooms, na.rm = TRUE) #3
mediana_rooms <- median(df$rooms, na.rm = TRUE) #2
mediana_sup_cubierta_test <- median(df_test$surface_covered, na.rm = TRUE) #118
mediana_sup_total_test <- median(df_test$surface_total, na.rm = TRUE) #120
mediana_bathrooms_test <- median(df_test$bathrooms, na.rm = TRUE) #3
mediana_rooms_test <- median(df_test$rooms, na.rm = TRUE) #2
df_test <- df_test %>%
mutate(rooms = replace_na(rooms, 2),
bathrooms = replace_na(bathrooms, 3),
surface_covered = replace_na(surface_covered, mediana_sup_cubierta_test),
surface_total = replace_na(surface_total, mediana_sup_total_test),)
df <- df %>%
mutate(rooms = replace_na(rooms, 2),
bathrooms = replace_na(bathrooms, 3),
surface_covered = replace_na(surface_covered, mediana_sup_cubierta),
surface_total = replace_na(surface_total, mediana_sup_total),)
df_test <- df_test %>%
mutate(property_typed = ifelse(df_test$property_type == "Casa", 1, 0))
rec1 <- recipe(price ~ surface_total + surface_covered + rooms + bedrooms + bathrooms + property_typed, data = df)
lm_mod <- linear_reg()
df <- df %>%
mutate(property_typed = ifelse(df$property_type == "Casa", 1, 0))
rec1 <- recipe(price ~ surface_total + surface_covered + rooms + bedrooms + bathrooms + property_typed, data = df)
lm_mod <- linear_reg()
wfl1 <- workflow() %>%
add_recipe(rec1) %>%
add_model(lm_mod)
set.seed(666)
data_split <- initial_split(df, prop = .7)
train <- training(data_split)
test <- testing(data_split)
fit1.1 <- wfl1 %>%
fit(data=train)
test_predict <- predict(fit1.1, new_data = test)
test_rmse.1.1 <- rmse(test_predict, truth = df$price, estimate = .pred)
test_rmse.1.1 <- rmse(test_predict, truth = price, estimate = .pred)
test_predict <- predict(fit1.1, new_data = test) %>%
bind_cols(test)
test_rmse.1.1 <- rmse(test_predict, truth = df$price, estimate = .pred)
View(test_predict)
test_rmse.1.1 <- rmse(test_predict, truth = df$price, estimate = .pred)
rlang::last_trace()
rlang::last_trace(drop = FALSE)
test_rmse.1.1 <- rmse(test_predict, truth = df$price, estimate = .pred, rows)
folds <- vfold_cv(df, v = 5)
fit_res2.1 <- fit_resamples(
wf1,
resamples = folds,
metrics = metric_set(rmse)
)
fit_res2.1 <- fit_resamples(
wfl1,
resamples = folds,
metrics = metric_set(rmse)
)
individual_rmse2.1 <- fit_res2.1 %>%
unnest(.metrics) %>%
select(id, .metric, .estimate)
individual_rmse2.1
mean(individual_rmse2.1$.estimate)
