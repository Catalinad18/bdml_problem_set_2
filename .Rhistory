colnames(t) <- c("property_id", "time_cfinanciero")
write_csv(t, "t2_til9002.csv")
getwd()
results <- gmapsdistance(origin = p,
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
coordenadas_propiedades[9000:9010]
results <- gmapsdistance(origin = "4.703842,-74.067853",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results <- gmapsdistance(origin = "4.70384,-74.067853",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results <- gmapsdistance(origin = "4.641624,-74.154555",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results <- gmapsdistance(origin = "4.641624+-74.154555",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results <- gmapsdistance(origin = "4.641624,-74.154555",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results1 <- gmapsdistance(origin = "4.641624+-74.154555",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results$Time
results1$Time
results <- gmapsdistance(origin = "4.703842,-74.067853",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results <- gmapsdistance(origin = "4.70384+,-74.067853",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
results <- gmapsdistance(origin = "4.70384+-74.067853",
destination = c("Torre Davivienda Centro Financiero, Bogota"),
mode = "driving",
combinations = "all",
traffic_model = "pessimistic",
dep_date = "2023-10-25", # provided as string in ISO 8601 format
dep_time = "12:00:00", # provided as string in HH:MM:SS format
key = Sys.getenv("GOOGLEGIDSTANCESKEY"))
##############################################################
#       Big Data y Machine Learning                          #
#  Taller 2: Árboles, Bagging, Random Forests y  Boosting    #
##############################################################
# Cargar datos y eliminar columnas que no son predictores ------------------------------------------------------------
# Clean environment
rm(list = ls())
#-------------------------------------------
require(pacman)
p_load(tidymodels,
caret,
rpart,
modeldata,
spatialsample,
tidyverse,
rio,
leaflet,
randomForest,
rattle,
spatialsample)
# Datos -------------------------------------------------------------------
sp_data <- readRDS("stores/Bases Finales/sp_data_final.rds")
new_data <- sp_data %>%
mutate(log_price=log(price)) %>% #Mejor log
select(-c(price, city, month, year, title, description, area, property_type, precio_por_mt2, piso_info,
geometry, operation_type)) %>%
mutate(across(
.cols = starts_with('dist'),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(across(c(surface_covered, bedrooms, bathrooms),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(ESTRATO=as.character(ESTRATO))
new_train<- new_data %>%
filter(type=="train") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_train)
dense_dtm_train <- readRDS("stores/Bases Finales/DTM_train.rds")
dense_dtm_test <- readRDS("stores/Bases Finales/DTM_test.rds")
new_data <- sp_data %>%
mutate(log_price=log(price)) %>% #Mejor log
select(-c(price, city, month, year, title, description, area, property_type, precio_por_mt2, piso_info,
geometry, operation_type)) %>%
mutate(across(
.cols = starts_with('dist'),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(across(c(surface_covered, bedrooms, bathrooms),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(ESTRATO=as.character(ESTRATO))
new_train<- new_data %>%
filter(type=="train") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_train)
new_test<- new_data %>%
filter(type=="test") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_test)
# Folds -------------------------------------------------------------------
#Sólo para probar, usamos un tipo diferente de splits espaciales (k means)
set.seed(123)
block_folds <- spatial_block_cv(new_train, v = 10)
autoplot(block_folds)
# Lasso -------------------------------------------------------------------
#Model
lasso <- linear_reg(penalty = tune(), mixture = 1) %>%
set_engine("glmnet")
lambda_grid_lasso <- grid_regular(penalty(), levels = 50) #Spatial cross validation
#Recipe
lasso_rec <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
#step_rm(NOMBRE) %>% #NOMBRE es la variable para el CV ahora, entonces no funcionan bien los efectos fijos. Vamos a ver.
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
#Workflow
lasso_wflow <-
workflow() %>%
add_recipe(lasso_rec) %>%
add_model(lasso)
#Tune grid
tune_result <- lasso_wflow %>%
tune_grid(resamples = block_folds,
grid = lambda_grid_lasso,
metrics = metric_set(mae),
control=control_grid(verbose=TRUE))
results_tuning_lasso <- tune_result %>%
collect_metrics()
tune_result %>%
collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1.5) +
scale_x_log10() +
theme(legend.position = "none") +
labs(title = "RMSE")
#Best fit
tune_best <- tune_result %>%
select_best(metric = "mae")
best_lasso <- linear_reg(penalty = tune_best$penalty, mixture = 1) %>%
set_engine("glmnet")
best_lasso_wflow <-
workflow() %>%
add_recipe(lasso_rec) %>%
add_model(best_lasso)
best_lasso_fit <-
best_lasso_wflow %>%
fit(new_train)
## Es interesante ver las variables que quedaron seleccionadas
coefs_lasso <- best_lasso_fit %>%
pull_workflow_fit() %>%
tidy()
View(coefs_lasso)
write_csv(coefs_lasso, "stores/Bases Finales/coefs_lasso.csv")
coefs_lasso <- read_csv("stores/Bases Finales/coefs_lasso.csv")
View(coefs_lasso)
selected_vars <- coefs_lasso$term[coefs_lasso$estimate!=0]
#Coefs Lasso para seleccionar variables
coefs_lasso <- read_csv("stores/Bases Finales/coefs_lasso.csv")
selected_vars <- coefs_lasso$term[coefs_lasso$estimate!=0][2:length(selected_vars)]
##############################################################
#       Big Data y Machine Learning                          #
#  Taller 2: Árboles, Bagging, Random Forests y  Boosting    #
##############################################################
# Cargar datos y eliminar columnas que no son predictores ------------------------------------------------------------
# Clean environment
rm(list = ls())
#-------------------------------------------
require(pacman)
p_load(tidymodels,
caret,
rpart,
modeldata,
spatialsample,
tidyverse,
rio,
leaflet,
randomForest,
rattle,
spatialsample)
# Datos -------------------------------------------------------------------
sp_data <- readRDS("stores/Bases Finales/sp_data_final.rds")
dense_dtm_train <- readRDS("stores/Bases Finales/DTM_train.rds")
dense_dtm_test <- readRDS("stores/Bases Finales/DTM_test.rds")
new_data <- sp_data %>%
mutate(log_price=log(price)) %>%
select(-c(price, city, month, year, title, description, piso_info, area,
precio_por_mt2, area, property_type_2,
geometry, operation_type)) %>%
mutate(across(
.cols = starts_with('dist'),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(across(c(surface_covered, bedrooms, bathrooms),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(ESTRATO=as.character(ESTRATO))
new_train<- new_data %>%
filter(type=="train") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_train)
new_test<- new_data %>%
filter(type=="test") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_test)
#Coefs Lasso para seleccionar variables
coefs_lasso <- read_csv("stores/Bases Finales/coefs_lasso.csv")
selected_vars <- coefs_lasso$term[coefs_lasso$estimate!=0][2:length(selected_vars)]
selected_vars <- coefs_lasso$term[coefs_lasso$estimate!=0]
selected_vars <- selected_vars[2:length(selected_vars)]
coefs_lasso <- read_csv("stores/Bases Finales/coefs_lasso.csv")
selected_vars <- coefs_lasso$term[coefs_lasso$estimate!=0]
selected_vars <- selected_vars[2:length(selected_vars)]
# Folds -------------------------------------------------------------------
set.seed(123)
block_folds <- spatial_block_cv(new_train, v = 10)
autoplot(block_folds)
#RECETA PARA LOS MODELOS --------------------------------------------------
#Recipe
#Con todas las variables
rec_trees_forests_boost <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
#Quitando lasso
rec_trees_forests_boost_select <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_rm(all_of(selected_vars)) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
#Model
tree <- decision_tree(
tree_depth = tune(),
min_n = tune()
) %>%
set_mode("regression")
tune_grid_tree <- grid_regular(
tree_depth(),
min_n(),
levels = c(10, 10)
)
#Con todas las variables
rec_trees_forests_boost <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
#Quitando lasso
rec_trees_forests_boost_select <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_rm(all_of(selected_vars)) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
# CART --------------------------------------------------------------------
#Model
tree <- decision_tree(
tree_depth = tune(),
min_n = tune()
) %>%
set_mode("regression")
tune_grid_tree <- grid_regular(
tree_depth(),
min_n(),
levels = c(10, 10)
)
#Workflows
workflow_tree <- workflow() %>%
add_recipe(rec_trees_forests_boost) %>%
add_model(tree)
workflow_tree_lasso <- workflow() %>%
add_recipe(rec_trees_forests_boost_select) %>%
add_model(tree)
#Tune grid
tune_tree <- workflow_tree %>%
tune_grid(resamples = block_folds,
grid = tune_grid_tree,
metrics = metric_set(mae),
control=control_grid(verbose=TRUE))
# Cargar datos y eliminar columnas que no son predictores ------------------------------------------------------------
# Clean environment
rm(list = ls())
#-------------------------------------------
require(pacman)
p_load(tidymodels,
caret,
rpart,
modeldata,
spatialsample,
tidyverse,
rio,
leaflet,
randomForest,
rattle,
spatialsample)
# Datos -------------------------------------------------------------------
sp_data <- readRDS("stores/Bases Finales/sp_data_final.rds")
dense_dtm_train <- readRDS("stores/Bases Finales/DTM_train.rds")
dense_dtm_test <- readRDS("stores/Bases Finales/DTM_test.rds")
new_data <- sp_data %>%
mutate(log_price=log(price)) %>%
select(-c(price, city, month, year, title, description, piso_info, area,
precio_por_mt2, area, property_type_2,
geometry, operation_type)) %>%
mutate(across(
.cols = starts_with('dist'),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(across(c(surface_covered, bedrooms, bathrooms),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(ESTRATO=as.character(ESTRATO))
new_train<- new_data %>%
filter(type=="train") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_train)
new_test<- new_data %>%
filter(type=="test") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_test)
#Coefs Lasso para seleccionar variables
coefs_lasso <- read_csv("stores/Bases Finales/coefs_lasso.csv")
selected_vars <- coefs_lasso$term[coefs_lasso$estimate!=0]
selected_vars <- selected_vars[2:length(selected_vars)]
# Folds -------------------------------------------------------------------
set.seed(123)
block_folds <- spatial_block_cv(new_train, v = 5)
autoplot(block_folds)
#RECETA PARA LOS MODELOS --------------------------------------------------
#Recipe
#Con todas las variables
rec_trees_forests_boost <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
#Quitando lasso
rec_trees_forests_boost_select <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_rm(all_of(selected_vars)) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
# CART --------------------------------------------------------------------
#Model
tree <- decision_tree(
tree_depth = tune(),
min_n = tune()
) %>%
set_mode("regression")
tune_grid_tree <- grid_regular(
tree_depth(),
min_n(),
levels = c(10, 5)
)
#Workflows
workflow_tree <- workflow() %>%
add_recipe(rec_trees_forests_boost) %>%
add_model(tree)
workflow_tree_lasso <- workflow() %>%
add_recipe(rec_trees_forests_boost_select) %>%
add_model(tree)
#Tune grid
tune_tree <- workflow_tree %>%
tune_grid(resamples = block_folds,
grid = tune_grid_tree,
metrics = metric_set(mae),
control=control_grid(verbose=TRUE))
results_tuning_tree <- tune_tree %>%
collect_metrics()
tune_tree_lasso <- workflow_tree_lasso %>%
tune_grid(resamples = block_folds,
grid = tune_grid_tree,
metrics = metric_set(mae),
control=control_grid(verbose=TRUE))
results_tuning_tree_lasso <- tune_tree_lasso %>%
collect_metrics()
new_data <- sp_data %>%
mutate(log_price=log(price)) %>%
select(-c(price, city, month, year, title, description, piso_info, area,
precio_por_mt2, area, property_type_2,
geometry, operation_type)) %>%
mutate(across(
.cols = starts_with('dist'),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(across(c(surface_covered, bedrooms, bathrooms),
.fns = list(sq = function(x) {x^2},
cube = function(x) {x^3}),
.names = "{.col}_{.fn}")) %>%
mutate(ESTRATO=as.character(ESTRATO))
new_train<- new_data %>%
filter(type=="train") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_train)
new_test<- new_data %>%
filter(type=="test") %>%
select(-c(type, property_id)) %>%
bind_cols(dense_dtm_test)
View(new_data)
selected_vars[selected_vars=="property_type"]
selected_vars[selected_vars=="property_type2.casa"]
selected_vars[selected_vars=="property_type2_Casa"]
selected_vars[selected_vars=="property_type_2_Casa"]
selected_vars <- coefs_lasso$term[coefs_lasso$estimate==0]
selected_vars <- selected_vars[2:length(selected_vars)]
selected_vars <- coefs_lasso$term[coefs_lasso$estimate==0]
drop_vars <-selected_vars[selected_vars!="property_type"]
"property_type"%in%drop_vars
selected_vars <- coefs_lasso$term[coefs_lasso$estimate==0]
#Quitando lasso
rec_trees_forests_boost_select <-
recipe(log_price ~ ., data = select(as_tibble(new_train), -geometry)) %>%
step_dummy(ESTRATO) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_rm(all_of(selected_vars)) %>%
step_normalize(all_numeric_predictors(), -all_outcomes())
tune_tree_lasso <- workflow_tree_lasso %>%
tune_grid(resamples = block_folds,
grid = tune_grid_tree,
metrics = metric_set(mae),
control=control_grid(verbose=TRUE))
results_tuning_tree_lasso <- tune_tree_lasso %>%
collect_metrics()
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
#Best Fit, Training and K-validation
best_tree <- select_best(tune_tree, metric = "mae")
best_tree_lasso <- select_best(tune_tree_lasso, metric = "mae")
1+1
